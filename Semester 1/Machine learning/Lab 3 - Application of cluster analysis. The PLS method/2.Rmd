# Ход работы

## 2. Выполнение расчётов по выбранной теме.

### 2.1 Получение и анализ данных

Для самостоятельной части лабораторной работы был выбран предлагаемый в задании датасет wine-quality <https://archive.ics.uci.edu/dataset/186/wine+quality.>. Данный датасет содержит информацию о разных характеристиках вина (плотность, уровень кислотности и т.п.). Целевой является категориальная переменная `quality`, описывающая качество данного вина по мнению экспертов. 

Была выполнена загрузка этого датасета и выведены основные параметры: размерность датафрейма X, а также количество элементов каждого класса Y.

```{r results = FALSE, message=FALSE, warning=FALSE}
library(mixOmics) # подключаем его
set.seed(5249) # для воспроизводимости результатов
```
```{r}
data <- read.csv("winequality-red.csv", sep = ";", header = TRUE, quote = "\"")
data$quality <- as.factor(data$quality)

X <- data[, -ncol(data)]
Y <- data$quality

dim(X) # проверяем размерность датафрейма X
summary(Y) # проверяем распределение классов
```

Как видно, в датасете имеется 1599 образцов, но их распределение по классам неравномерно: так, в классе качества `3` наблюдается 10 элементов, в то время как в классе качества `5` наблюдается 681.

Далее, с помощью PCA был проведён анализ основных источников вариации:

```{r}
# Применяем метод главных компонент, 10 компонент, центрируем и нормируем
pca.wine = pca(X, ncomp = 10, center = TRUE, scale = TRUE) 
plot(pca.wine)  # столбчатый график собственных значений
```

Из данного графика можно сделать вывод, что первые три комопненты объясняют существенную долю дисперсии (60%). Затем были cпроецированы метки классов на первые две компоненты:

```{r}
plotIndiv(pca.wine, group = data$quality, ind.names = FALSE,  
          legend = TRUE, title = 'PCA on wine, comp 1 - 2') 
```

Исходя из рисунка видно, что различные качества вин не разделяются и не группируются по двум основным компонентам данных.

### 2.2 Первоначальная модель sPLS-DA

Используем метод sPLS-DA, чтобы создать компоненты, которые лучше всего дифференцируют данные по классам.

```{r}
wine.splsda <- splsda(X, Y, ncomp = 10)  # устанавливаем ncomp равным 10 для сравнения с PCA в дальнейшем

plotIndiv(wine.splsda , 
          group = data$quality, ind.names = FALSE,  
          ellipse = TRUE, # доверительный эллипс 0.95
          legend = TRUE, title = 'PLSDA с доверительными эллипсами')

# использование max.dist для измерения чтобы сформировать границы классов
background = background.predict(wine.splsda, comp.predicted=2, dist = "max.dist")

# график классов проецированных на первые две компоненты sPLS-DA
plotIndiv(wine.splsda,
          group = data$quality, ind.names = FALSE,
          background = background, 
          legend = TRUE, title = "PLSDA с границами классов")
```

Исходя из рисунка видно, что различные качества вин не разделяются и не группируются по двум основным компонентам sPLS-DA.

### 2.3 Настройка sPLS-DA

### 2.3.1 Выбор количества комопнент

Выбор количества используемых компонент является важным решением и определяется результативностью модели PLS-DA, то есть её способностью правильно классифицировать новые данные. Именно для оценки результативности используется функция `perf()`. Стоит отметить, что данная функция использует кросс-валидацию. На основе выходных данных этой функции можно определить оптимальное количество компонент для анализа.

В этом примере используется кросс-валидация с разделением данных на 10 частей с 10 повторениями. 

Был построен график зависимости ошибки классификации от количества компонент. При этом, были выведены ошибки двух типов: общая частота ошибок (OER) и сбалансированная частота ошибок (BER). Также были использованы три разные метрики расстояний:

```{r}
# оцениваем производительность модели 
perf.splsda.wine <- perf(wine.splsda, validation = "Mfold", # кросс-валидация типа MFold
                          folds = 10, nrepeat = 10, # 5 частей, 10 повторений
                          progressBar = FALSE, auc = TRUE) # подключаем площадь под кривой (AUC)

# визуализация результатов оценки
plot(perf.splsda.wine, col = color.mixo(5:7), sd = TRUE,
     legend.position = "horizontal")
```

Исходя из графика можно сделать вывод, что лучше всего использовать 5 компонент. Связано это с тем, что начиная с 6-й компоненты значения ошибок изменяются на малые величины.

Существует также и другой способ выбрать оптимальное число компонент. В нём используется `$choice.ncomp` выходного объекта `perf()`. Он выполняет t-тесты для выявления существенных различий в средней частоте ошибок между компонентами.

```{r}
perf.splsda.wine$choice.ncomp # наилучшее значение количества компонент по мнению perf()
```

Если ориентироваться на показатель `max.dist`, то оптимальное число компонент равно 6.

### 2.3.2 Выбор количества переменных

Чтобы определить нужное количество переменных для формирования каждой компоненты, используется функция `tune.splsda()`. Она выполняется итеративно, по одной компоненте за раз. С помощью данной функции можно вычислить частоту ошибок классификации и усреднить её по частям (fold) и повторам. 

В качестве метрики расстояния использовалась `max.dist`, а кросс-валидация снова состояла из 10 частей и 10 повторений. Параметр `cpus` позволяет использовать распараллеливание вычислений.

Результаты настройки представлены на графике ниже. Ромб указывает на оптимальное количество переменных, которые необходимы для данной компоненты. При выборе `keepX` значения достигается наименьший процент ошибок классификации, определенный с помощью одностороннего t-критерия. Полосы ошибок указывают на стандартное отклонение при повторных перекрестных проверках частей.

```{r}
# cоздание списка значений keepX для тестирования
list.keepX <- c(1:10,  seq(20, 300, 10))

tune.splsda.wine <- tune.splsda(X, Y, ncomp = 6, # 6 компоненты
                                 validation = 'Mfold',
                                 folds = 10, nrepeat = 10, 
                                 dist = 'max.dist', # метрика max.dist
                                 measure = "BER", # используем сбалансированную частоту ошибок
                                 test.keepX = list.keepX,
                                 cpus = 2) # разрешение на распар

plot(tune.splsda.wine, col = color.jet(6)) # Вывод на график
```

Данный рисунок также помогает более правильно выбрать количество компонентов. Согласно методу `perf()` оптимальное количество компонент равно 6, что также подтверждает `tune.splsda()`:

```{r}
tune.splsda.wine$choice.ncomp$ncomp # оптимальное количество компонент согласно tune.splsda()
```

А количетсво переменных, которое будет использовано в каждой компоненте, характеризуется следующим выражением:

```{r}
tune.splsda.wine$choice.keepX # оптимальное количество переменных согласно tune.splsda()
```

Эти значения были сохранены для финальной, оптимизированной модели.

```{r}
optimal.ncomp <- tune.splsda.wine$choice.ncomp$ncomp
optimal.keepX <- tune.splsda.wine$choice.keepX[1:optimal.ncomp]
```

## 2.4 Финальная модель

Используя все указанные выше настроенные параметры, можно сформировать окончательную модель sPLS-DA.

```{r}
final.splsda <- splsda(X, Y, 
                       ncomp = optimal.ncomp, 
                       keepX = optimal.keepX)
```

## 2.5 Графики

### 2.5.1 Графики образцов (sample plots)

Чтобы показать распределение данных в скрытом пространстве, вновь спроецируем классы на две компоненты: 

```{r}
plotIndiv(final.splsda, comp = c(1,2), # графики, полученные с помощью финальной модели
          group = data$quality, ind.names = FALSE, # цвета по классам
          ellipse = TRUE, legend = TRUE, # доверительные эллипсы 0.95
          title = ' (a) sPLS-DA на SRBCT, компоненты 1 & 2')
```

Визуальная интерпретация всё ещё затруднена. CIM отображена ниже:

```{r}
# задаём легенду
legend=list(legend = levels(Y), # set of classes
            col = unique(color.mixo(Y)), # set of colours
            title = "Wine Quality", # legend title
            cex = 0.7) # legend size

# создаём CIM
cim <- cim(final.splsda, row.sideColors = color.mixo(Y), 
           legend = legend)
```

### 2.5.2 Графики переменных (Variable plots)

Также были выведены стабильности признаков. Под стабильностью подразумевается частота включения данного признака в компоненту. Её значение можно получить с помощью `perf.splsda.wine$features$stable`. Те признаки, у которых значение стабильности высоко, более важны для определенной компоненты. Признаки, стабильности которых высоки для первой компоненты, будут иметь низкую стабильность на других компонентах. 

Эти стабильности были выведены на график:

```{r}
# формируем новый perf() с использованием финальной настроенной модели
perf.splsda.wine <- perf(final.splsda, 
                          folds = 10, nrepeat = 10, # кросс-валидация
                          validation = "Mfold", dist = "max.dist",  # метрика max.dist 
                          progressBar = FALSE)

# выводим на график стабильность каждого признака для первых трёх компонент, 'h' означает гистограмму
par(mfrow=c(3,2))
plot(perf.splsda.wine$features$stable[[1]], type = 'h', 
     ylab = 'Stability', 
     xlab = 'Features', 
     main = '(a) Comp 1', las =2)
plot(perf.splsda.wine$features$stable[[2]], type = 'h', 
     ylab = 'Stability', 
     xlab = 'Features', 
     main = '(b) Comp 2', las =2)
plot(perf.splsda.wine$features$stable[[3]], type = 'h', 
     ylab = 'Stability', 
     xlab = 'Features',
     main = '(c) Comp 3', las =2)
plot(perf.splsda.wine$features$stable[[4]], type = 'h', 
     ylab = 'Stability', 
     xlab = 'Features',
     main = '(d) Comp 4', las =2)
plot(perf.splsda.wine$features$stable[[5]], type = 'h', 
     ylab = 'Stability', 
     xlab = 'Features',
     main = '(e) Comp 5', las =2)
```

Другой полезный график переменных — график круга корреляции:

```{r}
var.name.short <- substr(names(X), 1, 10)
plotVar(final.splsda, comp = c(1,5), var.names = list(var.name.short), cex = 3) # генерируем корреляционный круг
```

Данный график позволяет отследить корреляцию характеристик вин с определенными компонентами.

# 2.6 Предсказание

При проведении прогнозирования данные сначала должны быть разделены на обучающие и тестовые, чтобы были новые выборки для контрольной проверки. В противном случае существует риск “переобучения”, что приведет к завышенным показателям прогностических способностей.

```{r}
# Разделение датасета на обучающую и тестовую выборки в соотношении 80/20
ind <- sample(2, nrow(data), replace = TRUE, prob = c(0.8, 0.2))

# Отдельно формируем X и Y для обучающей и тестовой выборок
X.train <- data[ind == 1, -ncol(data)]  # Признаки для обучения (80%)
Y.train <- data[ind == 1, ncol(data)]   # Целевая переменная для обучения (80%)

X.test <- data[ind == 2, -ncol(data)]   # Признаки для тестирования (20%)
Y.test <- data[ind == 2, ncol(data)]    # Целевая переменная для тестирования (20%)
```

Затем модель была обучена:

```{r}
# обучение модели
train.splsda.wine <- splsda(X.train, Y.train, ncomp = optimal.ncomp, keepX = optimal.keepX)
```

После чего она была применена к тестовому набору с использованием метрики расстояния Махаланобиса (Mahalanobis distance).

```{r}
# используем модель на сете X test
predict.splsda.wine <- predict(train.splsda.wine, X.test, 
                                dist = "mahalanobis.dist")
```

Для оценки предсказательной способности может быть использована матрица ошибок (confusion matrix):

```{r}
# оценка предсказательной способности для 6 компонент
predict.comp5 <- predict.splsda.wine$class$mahalanobis.dist[,5]
table(factor(predict.comp5, levels = levels(Y)), Y.test)
```

Для класса `3`, модель предсказала класс `5` 30 раз, что, очевидно, является ошибкой. Для класса `5` (68 правильно предсказанных), результаты лучше. Также видно, что не удалось найти разницу между 7 классом и 6м. С классом №8 модель не справилась совсем.

### 2.7 Графики результативности (Perfomance Plots)

Для оценки результативности была использована ROC-кривая с 5 компонентами:

```{r}
auc.splsda = auroc(final.splsda, roc.comp = 5, print = FALSE) # AUROC для всех компонент
```

Здесь наглядно видно, что с классификацией 6-го класса модель справляется хуже всего.

# Вывод

В ходе лабораторной работы был исследован метод sPLS-DA в рамках задачи мультиклассовой классификации. В первой части работы работали с несбалансированным датасетом `srbct`, отличительной особенностью которого также является большое количество признаков при небольшой выборке образцов. Тем не менее, после настройки метод PLS-DA справился с задачей отлично, и в конце был получен результат в виде безупречной классификации всех образцов тестовой выборки.

Во второй части работы был использован датасет `winequality-red`, описывающий качество красного вина. Данный датасет тоже является несбалансированным. В связи с тем, что количество признаков здесь было намного больше, чем в первой части работы, двух компонент PLS-DA оказалось недостаточно для визуального разделения данных, что повлияло на качество большинства рисунков в данной работе. Тем не менее, модель была создана, настроена, обучена и протестирована. Конечное качество модели является хорошим для большинства классов (согласно AUROC), но класс качества `6` оказалось предсказать тяжелее всего: оценка AUROC `6 vs Others` составила `0,65`.
