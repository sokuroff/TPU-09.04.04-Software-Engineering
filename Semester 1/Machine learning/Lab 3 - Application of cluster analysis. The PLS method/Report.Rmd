---
title: "Лабораторная работа 3. Применение кластерного анализа. Метод PLS"
author: "Сокуров"
date: "28.10.2024"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Задание

Целью данной работы является формирование у магистрантов знаний в области статистики и навыков программирования на языке программирования R при решении задач кластеризации в биомедицине.

Изучите Статью (<http://mixomics.org/case-studies/splsda-srbct-case-study/>).

Выполните расчеты по Статье (<http://mixomics.org/case-studies/splsda-srbct-case-study/>) и проведите перекрестную проверку (cross validation) на языке программирования R.

Выполните аналогичные расчеты и предсказание (predict) для аналогичного по структуре набора данных выбранного самостоятельно (https://www.kaggle.com, datasetsearch) на языке программирования R.

Можно выбрать следующий набор данных: https://archive.ics.uci.edu/dataset/186/wine+quality.

Отчет сформируйте в RStudio в pdf-формате и прикрепите в качестве ответа.

# Ход работы

## 1. Выполнение расчётов по статье.

### 1.1 Получение и анализ данных

Необходимый датасет для работы находится в пакете mixOmics. Было выполнено подключение данного пакета, а также установлено зерно случайной генерации для воспроизводимости результатов:

```{r results = FALSE, message=FALSE, warning=FALSE}
library(mixOmics) # подключаем его
set.seed(5249) # для воспроизводимости результатов
```

Затем выполнили анализ датасета SRBCT (Маленькие круглые голубоклеточные опухоли). Для этого информацию об экспрессии генов поместили в матрицу X, а классы опухоли — в матрицу Y. Проверили размерность X и распределение классов в Y:

```{r}
data(srbct) # Получаем данные small round bull cell tumour
X <- srbct$gene # используем уровни экспрессии генов как матрицу X
Y <- srbct$class # используем классы как матрицу Y

dim(X) # проверяем размерность датафрейма X
summary(Y) # проверяем распределение классов
```

Видно, что распределение классов неравномерно: наименьшее количество элементов одного классов — 8, наибольшее количество элементов другого класса — 23, разница почти в 3 раза.

Как и в большинстве случаев при разработке моделей, хорошим первым шагом является изучение данных для определения основных источников вариаций. В данной статье был использован метод главных компонент (PCA):

```{r}
# Применяем метод главных компонент, 10 компонент, центрируем и нормируем
pca.srbct = pca(X, ncomp = 10, center = TRUE, scale = TRUE) 
plot(pca.srbct)  # столбчатый график собственных значений
```

Как видно из графика, первых двух компонент будет достаточно для того, чтобы объяснить существенную долю дисперсии данных. Затем, чтобы обнаружить источники вариаций было выполнено проецировании классов на эти компоненты:

```{r}
plotIndiv(pca.srbct, group = srbct$class, ind.names = FALSE,  
          legend = TRUE, title = 'PCA on SRBCT, comp 1 - 2') 
```

Исходя из рисунка видно, что различные типы опухолей не разделяются и не группируются по двум основным компонентам данных. Существуют кластеры, но они не объясняются значениями классов.

### 1.2 Первоначальная модель sPLS-DA

Используем метод sPLS-DA, чтобы создать компоненты, которые лучше всего дифференцируют данные на классы.

```{r}
srbct.splsda <- splsda(X, Y, ncomp = 10)  # устанавливаем ncomp равным 10 для сравнения с PCA в дальнейшем
```

Далее были спроецированы классы на первые две компоненты sPLS-DA с доверительными эллипсами:

```{r}
plotIndiv(srbct.splsda , 
          group = srbct$class, ind.names = FALSE,  
          ellipse = TRUE, # доверительный эллипс 0.95
          legend = TRUE, title = 'PLSDA с доверительными эллипсами')
```

Как видно, разделение на классы произведено намного лучше. После чего этот график был выведен с границами классов:

```{r}
# использование max.dist для измерения чтобы сформировать границы классов
background = background.predict(srbct.splsda, comp.predicted=2, dist = "max.dist")

# график классов проецированных на первые две компоненты sPLS-DA
plotIndiv(srbct.splsda,
          group = srbct$class, ind.names = FALSE,
          background = background, 
          legend = TRUE, title = "PLSDA с границами классов")
```

### 1.3 Настройка sPLS-DA

### 1.3.1 Выбор количества комопнент

Выбор количества используемых компонент является важным решением и определяется результативностью модели PLS-DA, то есть её способностью правильно классифицировать новые данные. Именно для оценки результативности используется функция `perf()`. Она использует кросс-валидацию внутри себя. На основе выходных данных этой функции можно определить оптимальное количество используемых компонент.

В этом примере используется кросс-валидация с разделением данных на 3 части и 10 повторениями. Однако, для датасетов с множеством выборок (экспериментов) рекомендуется разделение на 10 частей. Разделение на 3-5 частей подходит для небольших наборов. А те, у которых количество выборок совсем мало, должны использовать Leave-On-Out (LOO) валидацию. Причём, рекомендуется использовать 50-100 повторений, чтобы снизить долю влияния от случайного деления датасета на каждом шаге. 

Далее, для выяснения нужного количества компонент, был построен график зависимости ошибки классификации от количества компонент. При этом, были выведены ошибки двух типов: общая частота ошибок (OER) и сбалансированная частота ошибок (BER). Также были использованы три разные метрики расстояний:

```{r}
# оцениваем производительность модели 
perf.splsda.srbct <- perf(srbct.splsda, validation = "Mfold", # кросс-валидация типа MFold
                          folds = 5, nrepeat = 10, # 5 частей, 10 повторений
                          progressBar = FALSE, auc = TRUE) # подключаем площадь под кривой (AUC)

# визуализация результатов оценки
plot(perf.splsda.srbct, col = color.mixo(5:7), sd = TRUE,
     legend.position = "horizontal")
```

Исходя из графика можно сделать вывод, что лучше всего использовать три компоненты. Связано это с тем, что начиная с 4-й компоненты значения ошибок изменяются на малые величины.

Существует также и другой способ выбрать оптимальное число компонент. В нём используется $choice.ncomp выходного объекта perf(). Он выполняет t-тесты для выявления существенных различий в средней частоте ошибок между компонентами.
Если ориентироваться на показатель `max.dist`, то оптимальное число компонент равно 4. 

```{r}
perf.splsda.srbct$choice.ncomp # наилучшее значение количества компонент по мнению perf()
```

### 1.3.2 Выбор количества переменных

Чтобы определить нужное количество переменных для формирования каждой компоненты, используется функция tune.splsda(). Она выполняется итеративно, по одной компоненте за раз. С помощью данной функции можно вычислить частоту ошибок классификации и усреднить её по частям (fold) и повторам. Подходящее количество повторов 50-100. 

В качестве метрики расстояния использовалась `max.dist`, а кросс-валидация снова состояла из 5 частей и 10 повторов. Параметр `cpus` позволяет использовать распараллеливание вычислений.

Результаты настройки представлены на графике ниже. Ромб указывает на оптимальное количество переменных, которые необходимы для данной компоненты. При выборе keepX значения достигается наименьший процент ошибок классификации, определенный с помощью одностороннего t-критерия. Полосы ошибок указывают на стандартное отклонение при повторных перекрестных проверках частей.

```{r}
# cоздание списка значений keepX для тестирования
list.keepX <- c(1:10,  seq(20, 300, 10))


tune.splsda.srbct <- tune.splsda(X, Y, ncomp = 4, # 4 компоненты
                                 validation = 'Mfold',
                                 folds = 5, nrepeat = 10, 
                                 dist = 'max.dist', # метрика max.dist
                                 measure = "BER", # используем сбалансированную частоту ошибок
                                 test.keepX = list.keepX,
                                 cpus = 2) # разрешение на распараллеливание для снижения времени исполнения
plot(tune.splsda.srbct, col = color.jet(4)) # Вывод на график
```

Данный рисунок также помогает более правильно выбрать количество компонентов. Согласно методу perf() оптимальное количество компонент равно 4, но после использования tune.splsda() видно, что всё же оптимальное значение равняется 3.

```{r}
tune.splsda.srbct$choice.ncomp$ncomp # оптимальное количество компонент согласно tune.splsda()
```

А количетсво переменных, которое будет использовано в каждой компоненте, характеризуется следующим выражением:

```{r}
tune.splsda.srbct$choice.keepX # оптимальное количество переменных согласно tune.splsda()
```

Эти значения были сохранены для финальной, оптимизированной модели.

```{r}
optimal.ncomp <- tune.splsda.srbct$choice.ncomp$ncomp
optimal.keepX <- tune.splsda.srbct$choice.keepX[1:optimal.ncomp]
```

## 1.4 Финальная модель

Используя все указанные выше настроенные параметры, можно сформировать окончательную модель sPLS-DA.

```{r}
final.splsda <- splsda(X, Y, 
                       ncomp = optimal.ncomp, 
                       keepX = optimal.keepX)
```

## 1.5 Графики

### 1.5.1 Графики образцов (sample plots)

Чтобы показать распределение данных в скрытом пространстве, вновь спроецируем классы на две компоненты: 

```{r}
plotIndiv(final.splsda, comp = c(1,2), # графики, полученные с помощью финальной модели
          group = srbct$class, ind.names = FALSE, # цвета по классам
          ellipse = TRUE, legend = TRUE, # доверительные эллипсы 0.95
          title = ' (a) sPLS-DA на SRBCT, компоненты 1 & 2')

plotIndiv(final.splsda, comp = c(1,3), # графики, полученные с помощью финальной модели
          group = srbct$class, ind.names = FALSE,  # цвета по классам
          ellipse = TRUE, legend = TRUE, # доверительные эллипсы 0.95
          title = '(b) sPLS-DA on SRBCT, компоненты 1 & 3')
```

Как видно, эти графики разительно отличаются от тех, которые были получены в пункте 1.2 работы и связано это с тем, что в этот раз модель настроена. Гены, которые включены в 3 компоненту разделяют классы NB и RMS намного лучше, чем в первых двух компонентах. 

Карта кластерных изображений (CIM) показана на рисунке ниже. На ней показаны уровни экспрессии каждого гена (выбранного для создания компоненты) для каждого образца. Для получения CIM были использованы евклидово расстояние и метод полной агломерации. Можно видеть, что определенные наборы генов имели однородную экспрессию для разных классов. Например, почти половина генов имела высокую экспрессию при опухоли EWS (blue).

```{r}
# задаём легенду
legend=list(legend = levels(Y), # set of classes
            col = unique(color.mixo(Y)), # set of colours
            title = "Tumour Type", # legend title
            cex = 0.7) # legend size

# создаём CIM
cim <- cim(final.splsda, row.sideColors = color.mixo(Y), 
           legend = legend)
```

### 1.5.2 Графики переменных (Variable plots)

Также были выведены стабильности признаков. Под стабильностью подразумевается частота включения данного признака в компоненту. Её значение можно получить с помощью `perf.splsda.srbct$features$stable`. Те признаки, у которых значение стабильности высоко, более важны для определенной компоненты. Признаки, стабильности которых высоки для первой компоненты, будут иметь низкую стабильность на других компонентах. 

Эти стабильности были выведены на график:

```{r}
# формируем новый perf() с использованием финальной настроенной модели
perf.splsda.srbct <- perf(final.splsda, 
                          folds = 5, nrepeat = 10, # кросс-валидация
                          validation = "Mfold", dist = "max.dist",  # метрика max.dist 
                          progressBar = FALSE)

# выводим на график стабильность каждого признака для первых трёх компонент, 'h' означает гистограмму
par(mfrow=c(1,3))
plot(perf.splsda.srbct$features$stable[[1]], type = 'h', 
     ylab = 'Stability', 
     xlab = 'Features', 
     main = '(a) Comp 1', las =2)
plot(perf.splsda.srbct$features$stable[[2]], type = 'h', 
     ylab = 'Stability', 
     xlab = 'Features', 
     main = '(b) Comp 2', las =2)
plot(perf.splsda.srbct$features$stable[[3]], type = 'h', 
     ylab = 'Stability', 
     xlab = 'Features',
     main = '(c) Comp 3', las =2)
```

Другой полезный график переменных — график круга корреляции:

```{r}
var.name.short <- substr(srbct$gene.name[, 2], 1, 10) # формируем упрощённые названия генов

plotVar(final.splsda, comp = c(1,2), var.names = list(var.name.short), cex = 3) # генерируем корреляционный круг
```

Данный график позволяет отследить корреляцию генов с определенными компонентами. 

#1.6 Предсказание

При проведении прогнозирования данные PLS-DA сначала должны быть разделены на обучающие и тестовые, чтобы были новые выборки для оценки эффективности. В противном случае существует риск “переобучения”, что приведет к завышенным показателям прогностических способностей.

```{r}
train <- sample(1:nrow(X), 50) # случайно выбираем 50 элементов для обучения
test <- setdiff(1:nrow(X), train) # остальное для теста

# формируем наборы test & train 
X.train <- X[train, ]
X.test <- X[test,]
Y.train <- Y[train]
Y.test <- Y[test]
```

Затем модель обучается на основе обучающих данных. Стоит заметить, что в статье используются ранее рассчитанные значения optimal.keep X. В реальных сценариях модель обучения должна настраиваться самостоятельно. Необходимо, чтобы при обучении модели у неё не было доступа к данным тестирования. Это позволит снизить вероятность переобучения.

```{r}
# обучение модели
train.splsda.srbct <- splsda(X.train, Y.train, ncomp = optimal.ncomp, keepX = optimal.keepX)
```

Затем модель применяется к тестовому набору с использованием определенной метрики расстояния. В статье было использована метрика Махаланобиса (Mahalanobis distance).

```{r}
# используем модель на сете X test
predict.splsda.srbct <- predict(train.splsda.srbct, X.test, 
                                dist = "mahalanobis.dist")
```

Для оценки предсказательной способности может быть использована матрица ошибок (confusion matrix). Ниже представлена такая матрица для модели, которая использует только две первых компоненты. Была совершена только одна неправильная классификация: один образец был обозначен как `NB`, в то время как на самом деле он принадлежит `RMS` классу.

```{r}
# оценка предсказательной способности для первых двух компонент
predict.comp2 <- predict.splsda.srbct$class$mahalanobis.dist[,2]
table(factor(predict.comp2, levels = levels(Y)), Y.test)
```

Далее представлена матрица ошибок для модели с тремя компонентами. Точность классификации заметно увеличилась.

```{r}
# оценка предсказательной способности для первых трёх компонент
predict.comp3 <- predict.splsda.srbct$class$mahalanobis.dist[,3]
table(factor(predict.comp3, levels = levels(Y)), Y.test)
```

### 1.7 Графики результативности (Perfomance Plots)

Для оценки результативности часто используют ROC — это кривая, которая показывает зависимость между чувствительностью (или полнотой, True Positive Rate) и ложноположительной частотой (False Positive Rate) при разных порогах классификации. Кривая строится, изменяя порог вероятности, при котором модель решает, что объект относится к положительному классу. При высоком пороге классифицируются только уверенные положительные примеры, а при низком — модель допускает больше положительных предсказаний, в том числе ложных.

Также используется AUC (AUROC) — это площадь под ROC-кривой. Она измеряет, насколько хорошо модель различает классы. AUC принимает значения от 0 до 1. Чем больше значение, тем лучше модель. Чем больше площадь под ROC-кривой, тем лучше модель в целом, так как она указывает на высокую способность модели отличать положительные классы от отрицательных.

В данной работе значение AUC рассчитывается из обучающих кросс-валидационных наборов и в функции perf() (`perf.plsda.srbct$auc` для каждой пары классов (one vs. one) и `perf.plsda.srbct$auc.all`  для сравнения одного класса с остальными (one vs. all)).

Однако, критерии ROC и AUC могут не совсем точно оценивать результативность PLS-DA моделей. Связано это с тем, что ROC строится, изменяя порог классификации — порог вероятности, при котором модель решает, что объект относится к одному из классов, но классификация PLS-DA работает по-другому. Вместо того чтобы устанавливать порог вероятности, PLS-DA использует расстояние между наблюдением и центром каждого класса в многомерном пространстве. 

Поэтому ROC и AUC дают только приближенное представление о том, насколько модель PLS-DA различает классы. Они могут показывать, насколько далеко классы друг от друга, но не учитывают расстояние, использованное для предсказания, что иногда приводит к неполному или даже неточному отражению фактической производительности модели.

Однако, данные графики всё равно были выведены:

```{r}
auc.splsda = auroc(final.splsda, roc.comp = 1, print = FALSE) # AUROC для первой компоненты

auc.splsda = auroc(final.splsda, roc.comp = 3, print = FALSE) # AUROC для всех компонент
```

Данный рисунок (а) говорит о том, что может отличать BL от других классов с высоким уровнем истинно положительных результатов и низким уровнем ложноположительных результатов, но в то же время модель хуже отличает образцы из других классов, базируясь на компоненте 1.

Рисунок (б) включает все три компоненты и имеет идеальную точность классификации. Хоть модель и стала гораздо лучше путём подключения ещё двух компонент, но именно небольшой размер датасета позволяет получить идеальную классификацию.

